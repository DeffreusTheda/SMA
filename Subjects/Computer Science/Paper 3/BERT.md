{1:**Bidirectional Encoder Representations from [[Transformer Neural Networks|Transformers]]**}
abbr. {1:**BERT**},
introduced in 2018 by Google, it is a language model that use [[Self-supervised Learning|self-supervised learning]] and [[Encoder-only Transformer|encoder-only transformer architecture]].
<!--ID: 1741570833317-->


[Learn more](https://en.wikipedia.org/wiki/BERT_(language_model)).