Inspired by the human brain, which uses layers of interconnected neurons to process information.

Types:
- [[Recurrent Neural Networks]]
- [[Transformer Neural Networks]]
- [[Convolutional Neural Networks]]

## Process

### Training

### Deployment

- [[Cloud Computing]]
	- Offer scalability of resources based on demand
		- Efficient handling of high volumes of queries
		- No need for permanent resources
	- Flexible computing resources
	- Pay-as-you-go
		- Pay only what you need
- Edge computing: processing data closer to the source.
	- Reduce latency.
	- Improve response times.

## [[Biases]]

## Optimization

Reduce the complexity of machine learning models.
These techniques maintain model performance while decreasing computational requirements.
Together, these optimizations ensure that chatbots operate more efficiently and provide timely responses.

### Pruning

Pruning involves removing unnecessary neurons or connections.

- Significantly reduce the number of parameters
	- Faster inference times
	- Lower memory usage

### Quantization

Quantization reduces the precision of weights to lower bit sizes.

- Enhance models efficiency on hardware with limited precision capabilities.

### Knowledge Distillation

Knowledge distillation is the transfers of knowledge from a larger model to a smaller one.

May violate the terms of use of the larger model (allegedly, deepseek).
